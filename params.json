{"name":"Morse encoding decoding","tagline":"This project allows you to encode and decode Morse code using your device flashlight and camera. For decoding was used augmented reality library OpenCV 2","body":"# Morse_Encoding_Decoding\r\nThis project allows you to encode and decode Morse code using your device flashlight and camera. \r\nFor decoding was used augmented reality library OpenCV 2\r\n\r\nAll what you need to do:\r\n  0. Copy \"Morse Translation folders\" to your project\r\n  1. Add protocol declaration `<MorseAssistantDelegate>`\r\n  2. Init Morse assistant:\r\n    `MorseAssistant * myMorseAssistant = [MorseAssistant initMorse];`\r\n    `myMorseAssistant.delegate = self;`\r\n  3. For begin transmission Morse code with your device flashlight you need to call: \r\n   `[myMorseAssistant doCodingInMorseString:@\"Hello in Morse\" afterDelay:5.0];`\r\n  4. For begin decoding you need to call:\r\n  `[myMorseAssistant doDecoding];`\r\nThis delegate method -(void)UIUpdate; will be helpful, in this method you can get \r\nlive stream from camera and debug view, determine is flashing now or not, and get current morse transcript.\r\n  Example:\r\n\r\n    - (void)UIUpdate {\r\n       NSLog(@\"FlashValue: %f\", myMorseAssistant.m_detector->getFlashValue());\r\n    \r\n        _lblMorseCode.text = myMorseAssistant.strFlashSignalInText;\r\n\r\n        [imageVRealWorld setImage:myMorseAssistant.imageRealWorld];\r\n        [imageVDebug setImage:myMorseAssistant.imageDebug];\r\n    \r\n        if (myMorseAssistant.m_detector->isFlashing()) {\r\n            [imageAim setImage:[UIImage imageNamed:@\"aimGreen\"]];\r\n        }\r\n        else {\r\n            [imageAim setImage:[UIImage imageNamed:@\"aimRed\"]];\r\n        }\r\n    }\r\n\r\nBy default coding/decoding language determined by device's language, but you can change it by any time:\r\n`myMorseAssistant.iPreferLanguage = MorseCodeMessageLanguageEN;`","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}